# LEROBOT SOARM101 PROJECT
![Image](https://github.com/user-attachments/assets/bbfb79ad-0a2f-4016-ad69-124146166fcf)

---


# LeRobot SO-ARM 101 Setup Guide

ì´ ë¬¸ì„œëŠ” **LeRobot SO-ARM 101 (Leader / Follower)** ë¡œë´‡ì„ ì¡°ë¦½ ë° ì„¤ì •í•œ ë’¤,


**ëª¨í„° ì¸ì‹ â†’ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ â†’ ì›ê²© ì¡°ì •(Teleoperation)** ê¹Œì§€ ìˆ˜í–‰í•˜ëŠ” ì „ì²´ ê³¼ì •ì„ ì •ë¦¬í•œ ê°€ì´ë“œì…ë‹ˆë‹¤.


| Leader-Arm Axis      | Motor | Gear Ratio |
|-----------------------|-------|------------|
| Base / Shoulder Pan   | 1     | 1 / 191    |
| Shoulder Lift         | 2     | 1 / 345    |
| Elbow Flex            | 3     | 1 / 191    |
| Wrist Flex            | 4     | 1 / 147    |
| Wrist Roll            | 5     | 1 / 147    |
| Gripper               | 6     | 1 / 147    |

ë¡œë´‡ ì¡°ë¦½ ë° ëª¨í„°ì— ê´€í•œ ë‚´ìš© 
https://huggingface.co/docs/lerobot/so101


---

## ê°œë°œ í™˜ê²½

| í•­ëª©        | ë‚´ìš©                              |
| --------- | ------------------------------- |
| OS        | Windows 10 / 11                 |
| ì‹¤í–‰ í™˜ê²½     | **Visual Studio Code (VSCode)** |
| Python ë²„ì „ | 3.10 ì´ìƒ ê¶Œì¥                      |
| íŒ¨í‚¤ì§€ ì„¤ì¹˜    | `lerobot`           |
| ì‹¤í–‰ í„°ë¯¸ë„    | VSCode ë‚´ì¥ í„°ë¯¸ë„ (PowerShell)      |

>  *ì½˜ë‹¤ í™˜ê²½ì—ì„œë„ ê°€ëŠ¥í•˜ì§€ë§Œ, ë³¸ ì‹¤ìŠµì€ VSCode ê¸°ë³¸ Python í™˜ê²½ì—ì„œ ì§„í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.*
> 
> íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë°©ë²• https://huggingface.co/docs/lerobot/installation
> 

---

## 1. í¬íŠ¸ ì°¾ê¸°

ë¨¼ì € ë¡œë´‡ì˜ ì‹œë¦¬ì–¼ í¬íŠ¸ë¥¼ í™•ì¸í•©ë‹ˆë‹¤. 
ì»¨íŠ¸ë¡¤ ë³´ë“œì— USBí¬íŠ¸ì™€ ì–´ëŒ‘í„°ë¥¼ ì—°ê²°í•œ í›„ íŒŒì´ì¬ í„°ë¯¸ë„ì— ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.


ì˜ìƒ ì°¸ì¡° https://huggingface.co/docs/lerobot/so101

```bash
lerobot-find-port
```

* ì˜ˆ: `COM3`, `COM4`

---

## 2. ëª¨í„° ì„¤ì • (Motor Setup)

ìˆœì„œì— ë”°ë¼ ëª¨í„°ë“¤ì„ ì»¨íŠ¸ë¡¤ ë³´ë“œì— ì—°ê²°í•œ í›„ ê° ëª¨í„° IDë¥¼ ìˆœì„œëŒ€ë¡œ ë“±ë¡í•©ë‹ˆë‹¤.


ì˜ìƒ ì°¸ì¡° https://huggingface.co/docs/lerobot/so101


### Follower Arm ì„¤ì •

```bash
lerobot-setup-motors --robot.type=so101_follower --robot.port=COM3
```

**ì¶œë ¥ ì˜ˆì‹œ**

```
Connect the controller board to the 'gripper' motor only and press enter.
'gripper' motor id set to 6
...
'shoulder_pan' motor id set to 1
```

---

### Leader Arm ì„¤ì •

```bash
lerobot-setup-motors --teleop.type=so101_leader --teleop.port=COM4
```

**ì¶œë ¥ ì˜ˆì‹œ**

```
Connect the controller board to the 'gripper' motor only and press enter.
'gripper' motor id set to 6
...
'shoulder_pan' motor id set to 1
```

---

## 3. ìº˜ë¦¬ë¸Œë ˆì´ì…˜ (Calibration)

ëª¨ë“  ê´€ì ˆì˜ ìµœì†Œ/ìµœëŒ€/ì¤‘ì•™ ìœ„ì¹˜ë¥¼ ê¸°ë¡í•˜ì—¬ ë™ì‘ ë²”ìœ„ë¥¼ ë³´ì •í•©ë‹ˆë‹¤.
ëª…ë ¹ì–´ ì‹¤í–‰ í•œ í›„ Calibration ì˜ìƒì— ë”°ë¼ ê° ëª¨í„°ë“¤ì€ ì›€ì§ì—¬ì¤ë‹ˆë‹¤. 


ì˜ìƒ ì°¸ì¡° https://huggingface.co/docs/lerobot/so101

### ğŸ¦¿ Follower Arm Calibration

```bash
lerobot-calibrate --robot.type=so101_follower --robot.port=COM3 --robot.id=ty_follower_arm
```

**ê²°ê³¼ ì˜ˆì‹œ**

```
shoulder_pan    |    767 |   1978 |   3310
shoulder_lift   |    903 |    926 |   3278
elbow_flex      |    896 |   3109 |   3122
wrist_flex      |    844 |   2855 |   3194
wrist_roll      |    112 |   2088 |   3989
gripper         |   2046 |   2046 |   2047
Calibration saved to:
C:\Users\ê³½ë™í˜„\.cache\huggingface\lerobot\calibration\robots\so101_follower\ty_follower_arm.json
```

---

### Leader Arm Calibration

```bash
lerobot-calibrate --teleop.type=so101_leader --teleop.port=COM4 --teleop.id=ty_leader_arm
```

**ê²°ê³¼ ì˜ˆì‹œ**

```
shoulder_pan    |    730 |   1999 |   3238
shoulder_lift   |   2034 |   2042 |   4419
elbow_flex      |      0 |   2030 |   4095
wrist_flex      |    334 |   2361 |   2706
wrist_roll      |    128 |   2035 |   3971
gripper         |   2046 |   2047 |   2053
Calibration saved to:
C:\Users\ê³½ë™í˜„\.cache\huggingface\lerobot\calibration\teleoperators\so101_leader\ty_leader_arm.json
```

---

## 4. ì›ê²© ì¡°ì • (Teleoperation)

ë¦¬ë” ì•”(Leader Arm)ì˜ ì›€ì§ì„ì„ íŒ”ë¡œì›Œ ì•”(Follower Arm)ì— ì‹¤ì‹œê°„ìœ¼ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.


ì˜ìƒ ì°¸ì¡° https://huggingface.co/docs/lerobot/so101

```bash
lerobot-teleoperate \
  --robot.type=so101_follower  --robot.port=COM3 --robot.id=ty_follower_arm \
  --teleop.type=so101_leader   --teleop.port=COM4 --teleop.id=ty_leader_arm
```

* ë¦¬ë” ì•”ì„ ì›€ì§ì´ë©´ íŒ”ë¡œì›Œ ì•”ì´ ë™ì¼í•œ ë™ì‘ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
* ì—°ê²° ì„±ê³µ ì‹œ ì½˜ì†”ì— `"connected"` ë©”ì‹œì§€ê°€ í‘œì‹œë©ë‹ˆë‹¤.

![Image](https://github.com/user-attachments/assets/a6bd1568-5d39-4819-bbc1-994f7ba60087)

---

## ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„° ì €ì¥ ê²½ë¡œ

| êµ¬ë¶„           | ê²½ë¡œ                                                                                       |
| ------------ | ---------------------------------------------------------------------------------------- |
| Follower Arm | `~/.cache/huggingface/lerobot/calibration/robots/so101_follower/ty_follower_arm.json`    |
| Leader Arm   | `~/.cache/huggingface/lerobot/calibration/teleoperators/so101_leader/ty_leader_arm.json` |

---

## ìµœì¢… ì ê²€

* ê° ê´€ì ˆì˜ ì›€ì§ì„ì´ ìì—°ìŠ¤ëŸ¬ìš´ì§€ í™•ì¸
* ë¦¬ë” â†” íŒ”ë¡œì›Œ ì‹¤ì‹œê°„ ë°˜ì‘ í…ŒìŠ¤íŠ¸
* ë¬¸ì œê°€ ìˆì„ ê²½ìš° ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì¬ì§„í–‰

---

## Act Model

![Image](https://github.com/user-attachments/assets/a8fbd5a6-357a-4762-aa56-68399b7aaea4)

ACT Policy-based Robotic Sorting Task

In this project, we implemented a robotic sorting task using the ACT Policy model. The robot was trained to pick up two pens placed on a desk and move them into a container. The overall workflow consisted of dataset collection, additional data collection, model training, and execution of the trained robot.

To create the initial dataset, demonstration data was collected through direct human control of the leader arm. The follower arm replicated the movements of the leader arm in real time. During this process, two camerasâ€”a front-facing camera and a top-down cameraâ€”were used to capture the task environment and record visual observations along with the robot's motion data.

```
lerobot-record --robot.type=so101_follower --robot.port=COM3 --robot.id=my_awesome_follower_arm \
--robot.cameras="{ front: {type: opencv, index_or_path: 0, width: 640, height: 360, fps: 30},
top: {type: opencv, index_or_path: 1, width: 640, height: 360, fps: 30}}" \
--teleop.type=so101_leader --teleop.port=COM4 --teleop.id=my_awesome_leader_arm \
--display_data=false --dataset.repo_id=taeyoungss/Model_dataset2 \
--dataset.num_episodes=20 --dataset.single_task="Grab the pens and move it into the box"
```

After generating the initial dataset, additional demonstrations of the same task were collected to increase data diversity and improve the robustness of the model. The --resume=true option was used to append new data to the existing dataset without overwriting previous recordings.

```
lerobot-record --robot.type=so101_follower --robot.port=COM3 --robot.id=my_awesome_follower_arm \
--robot.cameras="{ front: {type: opencv, index_or_path: 0, width: 480, height: 640, fps: 30},
top: {type: opencv, index_or_path: 1, width: 640, height: 480, fps: 30}}" \
--teleop.type=so101_leader --teleop.port=COM4 --teleop.id=my_awesome_leader_arm \
--display_data=false --dataset.repo_id=taeyoungss/act_cleandesk \
--dataset.num_episodes=24 --dataset.single_task="Grab the stick and move it into the box" \
--resume=true
```

The collected dataset was then used to train the ACT Policy model. After training, the learned model was deployed on the robot and tested in a real-world environment to evaluate its performance.

```
lerobot-record \
--robot.type=so101_follower \
--robot.port=COM3 \
--robot.id=my_awesome_follower_arm \
--robot.cameras="{ front: {type: opencv, index_or_path: 0, width: 640, height: 360, fps: 15},
top: {type: opencv, index_or_path: 1, width: 640, height: 360, fps: 15}}" \
--display_data=false \
--dataset.repo_id=taeyoungss/eval_Act_Model2 \
--dataset.num_episodes=5 \
--dataset.reset_time_s=5 \
--dataset.single_task="Grab the stick and move it into the box" \
--policy.path=taeyoungss/Act_Model
```

Experimental results showed that the robot was able to successfully detect, grasp, and move the pens into the container. The overall success rate was approximately 70%. Failures mainly occurred due to slippage during grasping or when the pens were placed in positions not sufficiently represented in the training dataset.

This experiment demonstrates that the ACT Policy model can be effectively applied to simple robotic manipulation and organization tasks. Future improvements, such as increasing the dataset size and extending the training duration, are expected to further enhance the robotâ€™s performance and reliability.



![Image](https://github.com/user-attachments/assets/5ded7f40-a024-43bf-a796-51d15e0cda69)

You can download and watch the model demonstration video from the link below.


https://huggingface.co/taeyoungss/eval_Act_Model




# References 

https://hyundoil.tistory.com/469


https://github.com/huggingface/lerobot


https://huggingface.co/docs/lerobot/so101

https://www.youtube.com/watch?v=ElZvzKRt9g8&t=150s

https://roboseasy.github.io/docs/physical-ai/lerobot/so-arm/software/record-replay

